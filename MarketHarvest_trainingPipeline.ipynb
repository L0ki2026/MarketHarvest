{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/L0ki2026/MarketHarvest/blob/main/MarketHarvest_trainingPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Download Data"
      ],
      "metadata": {
        "id": "co-n6vpOjbfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Data from the web\n",
        "!wget -O cit_det.zip \"https://mavmatrix.uta.edu/context/cse_datasets/article/1000/type/native/viewcontent\"\n",
        "!wget -O apple_data.tar.gz \"https://conservancy.umn.edu/bitstreams/3ef26f04-6467-469b-9857-f443ffa1bb61/download\"\n",
        "\n",
        "# Unzip the data\n",
        "!unzip /content/cit_det.zip\n",
        "!tar -xvzf /content/apple_data.tar.gz\n",
        "!unzip /content/CitDet-test.zip\n",
        "!unzip /content/CitDet-train.zip\n",
        "\n",
        "# Remove zip files\n",
        "!rm /content/CitDet-test.zip /content/CitDet-train.zip /content/cit_det.zip /content/MANIFEST.TXT\n",
        "!rm /content/apple_data.tar.gz\n",
        "\n",
        "# Create file structure\n",
        "!mkdir citrus_data\n",
        "!mv /content/test citrus_data\n",
        "!mv /content/train citrus_data\n",
        "!mv detection apple_data\n",
        "!mv /content/citrus_data/test/images/* /content/citrus_data/train/images/\n",
        "!mv /content/citrus_data/test/masks/* /content/citrus_data/train/masks/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHUrqZnak6_3",
        "outputId": "6873f3b9-0449-4c37-9b78-488f7d3d80c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-07 01:42:20--  https://mavmatrix.uta.edu/context/cse_datasets/article/1000/type/native/viewcontent\n",
            "Resolving mavmatrix.uta.edu (mavmatrix.uta.edu)... 13.57.92.51, 50.18.241.247\n",
            "Connecting to mavmatrix.uta.edu (mavmatrix.uta.edu)|13.57.92.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://mavmatrix.uta.edu/cgi/viewcontent.cgi?params=/context/cse_datasets/article/1000/type/native/&path_info= [following]\n",
            "--2025-02-07 01:42:22--  https://mavmatrix.uta.edu/cgi/viewcontent.cgi?params=/context/cse_datasets/article/1000/type/native/&path_info=\n",
            "Reusing existing connection to mavmatrix.uta.edu:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1103158596 (1.0G) [application/zip]\n",
            "Saving to: ‘cit_det.zip’\n",
            "\n",
            "cit_det.zip          59%[==========>         ] 621.28M  17.0MB/s    eta 28s    ^C\n",
            "--2025-02-07 01:43:01--  https://conservancy.umn.edu/bitstreams/3ef26f04-6467-469b-9857-f443ffa1bb61/download\n",
            "Resolving conservancy.umn.edu (conservancy.umn.edu)... 128.101.65.121\n",
            "Connecting to conservancy.umn.edu (conservancy.umn.edu)|128.101.65.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://conservancy.umn.edu/server/api/core/bitstreams/3ef26f04-6467-469b-9857-f443ffa1bb61/content [following]\n",
            "--2025-02-07 01:43:02--  https://conservancy.umn.edu/server/api/core/bitstreams/3ef26f04-6467-469b-9857-f443ffa1bb61/content\n",
            "Reusing existing connection to conservancy.umn.edu:443.\n",
            "HTTP request sent, awaiting response... 200 200\n",
            "Length: 1825397590 (1.7G) [application/gzip]\n",
            "Saving to: ‘apple_data.tar.gz’\n",
            "\n",
            "apple_data.tar.gz     5%[>                   ] 103.94M  17.8MB/s    eta 1m 57s ^C\n",
            "Archive:  /content/cit_det.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/cit_det.zip or\n",
            "        /content/cit_det.zip.zip, and cannot find /content/cit_det.zip.ZIP, period.\n",
            "detection/test/images/dataset2_back_630.png\n",
            "detection/train/masks/20150919_174151_image11.png\n",
            "detection/train/images/20150919_174730_image161.png\n",
            "detection/train/masks/20150921_131346_image1121.png\n",
            "detection/train/masks/20150921_131234_image546.png\n",
            "detection/test/images/dataset3_front_510.png\n",
            "detection/train/images/20150921_131346_image1121.png\n",
            "detection/train/images/\n",
            "detection/train/masks/20150921_132245_image396.png\n",
            "detection/train/masks/20150921_131453_image676.png\n",
            "detection/train/masks/20150921_131833_image296.png\n",
            "detection/train/images/20150919_174151_image301.png\n",
            "detection/train/images/20150921_132038_image76.png\n",
            "detection/train/masks/20150921_131453_image1196.png\n",
            "detection/train/images/20150921_131346_image51.png\n",
            "detection/train/masks/20150921_132038_image1241.png\n",
            "detection/test/images/dataset4_front_900.png\n",
            "detection/test/images/dataset4_front_1020.png\n",
            "detection/train/images/20150919_174730_image216.png\n",
            "detection/train/images/20150921_131453_image1196.png\n",
            "detection/train/images/20150921_131729_image116.png\n",
            "detection/train/images/20150921_132038_image1241.png\n",
            "detection/train/masks/20150919_174151_image601.png\n",
            "detection/train/images/20150921_131453_image281.png\n",
            "detection/train/masks/20150921_131346_image996.png\n",
            "detection/train/masks/20150919_174151_image181.png\n",
            "detection/train/images/20150921_131346_image961.png\n",
            "detection/train/masks/20150921_131346_image1021.png\n",
            "detection/train/masks/20150921_132038_image6.png\n",
            "detection/train/masks/20150921_131625_image76.png\n",
            "detection/train/images/20150921_131234_image681.png\n",
            "detection/train/images/20150921_131625_image156.png\n",
            "detection/train/masks/20150921_132038_image271.png\n",
            "detection/train/images/20150921_131453_image966.png\n",
            "detection/train/images/20150921_131346_image1021.png\n",
            "detection/train/images/20150921_131833_image76.png\n",
            "detection/train/masks/20150921_131833_image196.png\n",
            "detection/test/images/dataset2_front_1050.png\n",
            "detection/train/images/20150921_132038_image126.png\n",
            "detection/train/masks/20150921_131346_image631.png\n",
            "detection/train/images/20150921_131833_image316.png\n",
            "detection/train/masks/20150921_131453_image636.png\n",
            "detection/train/images/20150919_174730_image386.png\n",
            "detection/train/masks/20150921_131625_image656.png\n",
            "detection/train/images/20150921_132245_image261.png\n",
            "detection/test/images/dataset2_front_90.png\n",
            "detection/train/masks/20150919_174151_image81.png\n",
            "detection/train/images/20150921_131833_image161.png\n",
            "detection/train/images/20150921_132038_image921.png\n",
            "detection/train/masks/20150919_174730_image66.png\n",
            "detection/train/masks/20150919_174151_image236.png\n",
            "detection/test/images/dataset3_back_1320.png\n",
            "detection/train/images/20150919_174730_image116.png\n",
            "detection/train/images/20150921_131453_image601.png\n",
            "detection/train/masks/20150919_174730_image321.png\n",
            "detection/test/images/dataset2_front_510.png\n",
            "detection/test/images/dataset1_front_1231.png\n",
            "detection/train/images/20150921_131453_image181.png\n",
            "detection/train/images/20150921_131346_image596.png\n",
            "detection/train/images/20150919_174151_image201.png\n",
            "detection/test/images/dataset1_back_631.png\n",
            "detection/train/masks/20150921_131833_image516.png\n",
            "detection/train/images/20150921_131234_image581.png\n",
            "detection/train/masks/20150921_131625_image1091.png\n",
            "detection/train/images/20150919_174730_image41.png\n",
            "detection/train/images/20150921_131729_image451.png\n",
            "detection/train/images/20150919_174151_image101.png\n",
            "detection/test/images/dataset3_back_270.png\n",
            "detection/train/images/20150921_131833_image386.png\n",
            "detection/train/images/20150921_131234_image11.png\n",
            "detection/train/masks/20150921_131234_image306.png\n",
            "detection/train/images/20150921_131833_image216.png\n",
            "detection/train/masks/20150921_131453_image801.png\n",
            "detection/train/images/20150919_174730_image286.png\n",
            "detection/train/images/20150919_174730_image551.png\n",
            "detection/test/images/dataset3_front_480.png\n",
            "detection/test/images/dataset3_front_900.png\n",
            "detection/train/masks/20150921_132245_image786.png\n",
            "detection/train/masks/20150921_132038_image496.png\n",
            "detection/train/masks/20150921_131453_image1056.png\n",
            "detection/train/masks/20150919_174151_image136.png\n",
            "detection/train/masks/20150921_132038_image1101.png\n",
            "detection/train/images/20150921_131453_image236.png\n",
            "detection/train/masks/20150921_132038_image66.png\n",
            "detection/train/masks/20150919_174730_image221.png\n",
            "detection/train/images/20150921_131234_image636.png\n",
            "detection/train/images/20150921_131453_image1056.png\n",
            "detection/train/images/20150921_132245_image751.png\n",
            "detection/train/images/20150921_132038_image1101.png\n",
            "detection/train/images/20150921_131833_image116.png\n",
            "detection/train/images/20150921_131234_image481.png\n",
            "detection/train/masks/20150921_131833_image416.png\n",
            "detection/train/masks/20150919_174730_image486.png\n",
            "detection/train/images/20150921_131346_image496.png\n",
            "detection/train/masks/20150921_131833_image71.png\n",
            "detection/test/images/dataset4_front_870.png\n",
            "detection/train/masks/20150921_131729_image116.png\n",
            "detection/train/masks/20150921_131346_image1.png\n",
            "detection/train/images/20150921_131625_image1091.png\n",
            "detection/test/images/dataset3_back_660.png\n",
            "detection/train/masks/20150921_132038_image131.png\n",
            "detection/train/images/20150919_174730_image186.png\n",
            "detection/train/masks/20150919_174151_image36.png\n",
            "detection/train/masks/20150921_131453_image701.png\n",
            "detection/train/masks/20150921_131346_image1146.png\n",
            "detection/train/masks/20150921_131833_image321.png\n",
            "detection/train/images/20150921_131453_image671.png\n",
            "detection/train/images/20150921_131346_image816.png\n",
            "\n",
            "gzip: stdin: unexpected end of file\n",
            "tar: Unexpected EOF in archive\n",
            "tar: Unexpected EOF in archive\n",
            "tar: Error is not recoverable: exiting now\n",
            "unzip:  cannot find or open /content/CitDet-test.zip, /content/CitDet-test.zip.zip or /content/CitDet-test.zip.ZIP.\n",
            "unzip:  cannot find or open /content/CitDet-train.zip, /content/CitDet-train.zip.zip or /content/CitDet-train.zip.ZIP.\n",
            "rm: cannot remove '/content/CitDet-test.zip': No such file or directory\n",
            "rm: cannot remove '/content/CitDet-train.zip': No such file or directory\n",
            "rm: cannot remove '/content/MANIFEST.TXT': No such file or directory\n",
            "mv: cannot stat '/content/test': No such file or directory\n",
            "mv: cannot stat '/content/train': No such file or directory\n",
            "mv: cannot stat '/content/citrus_data/test/images/*': No such file or directory\n",
            "mv: cannot stat '/content/citrus_data/test/masks/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create Bounding Boxes"
      ],
      "metadata": {
        "id": "HELlkz0ujeRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision.io import read_image\n",
        "from torchvision.ops import masks_to_boxes\n",
        "import numpy as np\n",
        "\n",
        "# Paths\n",
        "img_folder = r\"/content/apple_data/train/images\"\n",
        "mask_folder = r\"/content/apple_data/train/masks\"\n",
        "output_folder = r\"/content/apple_data/train/masks\"\n",
        "\n",
        "\n",
        "# Iterate through all images and masks\n",
        "for mask_file in os.listdir(mask_folder):\n",
        "    # Ensure it's a valid image file\n",
        "    if not mask_file.endswith(('.png', '.jpg', '.jpeg', '.tiff')):\n",
        "        continue\n",
        "\n",
        "    # Paths for the current image and mask\n",
        "    mask_path = os.path.join(mask_folder, mask_file)\n",
        "    img_path = os.path.join(img_folder, mask_file)\n",
        "\n",
        "    # Read the mask\n",
        "    mask = read_image(mask_path)\n",
        "\n",
        "    # Get unique object IDs (skipping background)\n",
        "    obj_ids = torch.unique(mask)\n",
        "    obj_ids = obj_ids[1:]\n",
        "\n",
        "    # Create binary masks for each object\n",
        "    masks = mask == obj_ids[:, None, None]\n",
        "\n",
        "    # Generate bounding boxes\n",
        "    boxes = masks_to_boxes(masks)\n",
        "\n",
        "    # Normalize boxes for YOLO format\n",
        "    img_height, img_width = mask.shape[1:]  # H, W\n",
        "    yolo_boxes = []\n",
        "    for box in boxes:\n",
        "        x_min, y_min, x_max, y_max = box\n",
        "        x_center = (x_min + x_max) / 2 / img_width\n",
        "        y_center = (y_min + y_max) / 2 / img_height\n",
        "        width = (x_max - x_min) / img_width\n",
        "        height = (y_max - y_min) / img_height\n",
        "        yolo_boxes.append([0, x_center.item(), y_center.item(), width.item(), height.item()])\n",
        "\n",
        "    # Save annotations to a YOLO format file\n",
        "    yolo_file = os.path.join(output_folder, os.path.splitext(mask_file)[0] + \".txt\")\n",
        "    with open(yolo_file, \"w\") as f:\n",
        "        for box in yolo_boxes:\n",
        "            f.write(\" \".join(map(str, box)) + \"\\n\")\n",
        "\n",
        "print(f\"Annotations saved in YOLO format to: {output_folder}\")\n"
      ],
      "metadata": {
        "id": "UWgsiHiSjhjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebdca94-6b2a-4705-b637-5903e82b9ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations saved in YOLO format to: /content/apple_data/train/masks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for citrus\n",
        "import cv2\n",
        "from skimage.measure import label, regionprops\n",
        "\n",
        "# Paths\n",
        "mask_folder = r\"/content/citrus_data/train/masks\"\n",
        "output_folder = r\"/content/citrus_data/train/masks\"\n",
        "\n",
        "# Ensure output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Process each mask\n",
        "for mask_file in os.listdir(mask_folder):\n",
        "    if not mask_file.endswith(('.png', '.jpg', '.jpeg', '.tiff')):\n",
        "        continue\n",
        "\n",
        "    # Read the mask as a grayscale image\n",
        "    mask_path = os.path.join(mask_folder, mask_file)\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Apply connected component labeling\n",
        "    labeled_mask = label(mask > 1)  # All greater than 1 pixels are considered part of a component\n",
        "\n",
        "    # Extract bounding boxes from labeled regions\n",
        "    img_height, img_width = mask.shape\n",
        "    yolo_boxes = []\n",
        "\n",
        "    for region in regionprops(labeled_mask):\n",
        "        # Get bounding box (min_row, min_col, max_row, max_col)\n",
        "        min_row, min_col, max_row, max_col = region.bbox\n",
        "\n",
        "        # Convert to YOLO format (x_center, y_center, width, height)\n",
        "        x_center = ((min_col + max_col) / 2) / img_width\n",
        "        y_center = ((min_row + max_row) / 2) / img_height\n",
        "        width = (max_col - min_col) / img_width\n",
        "        height = (max_row - min_row) / img_height\n",
        "\n",
        "        yolo_boxes.append([1, x_center, y_center, width, height])  # Class ID is set to 1\n",
        "\n",
        "    # Save annotations in YOLO format\n",
        "    yolo_file = os.path.join(output_folder, os.path.splitext(mask_file)[0] + \".txt\")\n",
        "    with open(yolo_file, \"w\") as f:\n",
        "        for box in yolo_boxes:\n",
        "            f.write(\" \".join(map(str, box)) + \"\\n\")\n",
        "\n",
        "print(f\"Annotations saved in YOLO format to: {output_folder}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1e4QR64bRS0",
        "outputId": "3779b03e-7e74-4d12-ef54-3c618c6de898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations saved in YOLO format to: /content/citrus_data/train/masks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove segmentation masks\n",
        "!rm -rf /content/citrus_data/train/masks/*.png\n",
        "!rm -rf /content/apple_data/train/masks/*.png\n",
        "\n",
        "# Create final file structure\n",
        "!mkdir -p combined_data/images/train combined_data/images/val combined_data/labels/train combined_data/labels/val\n",
        "\n",
        "# Move images and annotations into the correct folder\n",
        "!mv /content/citrus_data/train/images/* /content/combined_data/images/train\n",
        "!mv /content/apple_data/train/images/* /content/combined_data/images/train\n",
        "\n",
        "!mv /content/apple_data/train/masks/* /content/combined_data/labels/train/\n",
        "!mv /content/citrus_data/train/masks/* /content/combined_data/labels/train/\n",
        "\n",
        "# Remove old files\n",
        "!rm -rf /content/citrus_data /content/apple_data"
      ],
      "metadata": {
        "id": "BIxgTZJvbc3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example YAML content\n",
        "yaml_content = \"\"\"\n",
        "path: /content/combined_data\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "\n",
        "# Classes (80 COCO classes)\n",
        "names:\n",
        "    0: apple\n",
        "    1: citrus\n",
        "\"\"\"\n",
        "\n",
        "# Write to a YAML file\n",
        "with open(\"config.yaml\", \"w\") as file:\n",
        "    file.write(yaml_content)\n",
        "\n",
        "print(\"YAML file created!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDahosgosRCC",
        "outputId": "da2bcf43-79a8-494c-fb52-4ff2f1045770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML file created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Split into training and testing set"
      ],
      "metadata": {
        "id": "JXg8RLh5jh89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import shutil\n",
        "\n",
        "# Set your dataset paths\n",
        "images_path = r\"/content/combined_data/images/train\"\n",
        "annotations_path = r\"/content/combined_data/labels/train\"\n",
        "\n",
        "# Destination paths\n",
        "train_images_dest = r\"/content/combined_data/images/train\"\n",
        "val_images_dest = r\"/content/combined_data/images/val\"\n",
        "train_annotations_dest = r\"/content/combined_data/labels/train\"\n",
        "val_annotations_dest = r\"/content/combined_data/labels/val\"\n",
        "\n",
        "# Create necessary folders\n",
        "os.makedirs(train_images_dest, exist_ok=True)\n",
        "os.makedirs(val_images_dest, exist_ok=True)\n",
        "os.makedirs(train_annotations_dest, exist_ok=True)\n",
        "os.makedirs(val_annotations_dest, exist_ok=True)\n",
        "\n",
        "# Get the list of all images and shuffle them\n",
        "images = [f for f in os.listdir(images_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "random.shuffle(images)\n",
        "\n",
        "# Split the data into 80% train and 20% val\n",
        "split_ratio = 0.80\n",
        "split_index = int(len(images) * split_ratio)\n",
        "\n",
        "train_images = images[:split_index]\n",
        "val_images = images[split_index:]\n",
        "\n",
        "# Function to move files\n",
        "def move_files(file_list, src_images_path, src_annotations_path, dest_images_path, dest_annotations_path):\n",
        "    for image in file_list:\n",
        "        # Move image\n",
        "        shutil.move(os.path.join(src_images_path, image), os.path.join(dest_images_path, image))\n",
        "\n",
        "        # Move corresponding annotation\n",
        "        annotation_file = image.replace('.png', '.txt').replace('.jpg', '.txt').replace('.jpeg', '.txt')\n",
        "        shutil.move(os.path.join(src_annotations_path, annotation_file), os.path.join(dest_annotations_path, annotation_file))\n",
        "\n",
        "# Move train files\n",
        "move_files(train_images, images_path, annotations_path, train_images_dest, train_annotations_dest)\n",
        "\n",
        "# Move val files\n",
        "move_files(val_images, images_path, annotations_path, val_images_dest, val_annotations_dest)\n",
        "\n",
        "print(\"Train-Test split completed successfully!\")\n"
      ],
      "metadata": {
        "id": "pMpn7ZWJjlVT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969f1f37-bfe2-49c6-c30d-c66be9299cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train-Test split completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train Model"
      ],
      "metadata": {
        "id": "3QeJYVDgjlvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAoTLcUVsBJE",
        "outputId": "8baa7825-3f73-4fa2-abd4-0d13343b1be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.63-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.63-py3-none-any.whl (910 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m910.2/910.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.63 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "model = YOLO(\"yolo11m.pt\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    results = model.train(data=\"config.yaml\", epochs=100, imgsz=320, batch=4, device=0, patience=10)\n",
        "  else:\n",
        "    results = model.train(data=\"config.yaml\", epochs=100, imgsz=320, batch=4, patience=10)"
      ],
      "metadata": {
        "id": "zNGFLluFjnad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1cc0793-13b4-4ce2-a804-abce43f2277f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'yolo11m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38.8M/38.8M [00:00<00:00, 233MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.63 🚀 Python-3.11.11 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11m.pt, data=config.yaml, epochs=100, time=None, patience=10, batch=4, imgsz=320, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 20.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 23        [16, 19, 22]  1   1412566  ultralytics.nn.modules.head.Detect           [2, [256, 512, 512]]          \n",
            "YOLO11m summary: 409 layers, 20,054,550 parameters, 20,054,534 gradients, 68.2 GFLOPs\n",
            "\n",
            "Transferred 643/649 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 115MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/combined_data/labels/train... 999 images, 0 backgrounds, 0 corrupt: 100%|██████████| 999/999 [00:02<00:00, 450.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/combined_data/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/combined_data/labels/val... 250 images, 0 backgrounds, 0 corrupt: 100%|██████████| 250/250 [00:01<00:00, 152.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/combined_data/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      1.35G      2.745      1.785     0.9105        145        320: 100%|██████████| 250/250 [01:04<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:11<00:00,  2.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.471      0.363      0.328      0.121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      1.17G      2.673      1.439     0.8637        327        320: 100%|██████████| 250/250 [00:57<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:09<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.442      0.338      0.301     0.0887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      1.16G      2.627      1.408      0.858        105        320: 100%|██████████| 250/250 [00:56<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:09<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172       0.57      0.382        0.4      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100      1.15G      2.565      1.379     0.8484        176        320: 100%|██████████| 250/250 [00:55<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:10<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.547      0.348      0.377      0.145\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      1.13G      2.529      1.328      0.844        399        320: 100%|██████████| 250/250 [00:57<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:10<00:00,  3.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.583      0.393      0.421      0.171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100      1.18G      2.457      1.274       0.84        304        320: 100%|██████████| 250/250 [00:56<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:10<00:00,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.586      0.392      0.411      0.159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      1.18G      2.406      1.272     0.8353        140        320: 100%|██████████| 250/250 [00:56<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:10<00:00,  3.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.601      0.392      0.418      0.168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      1.12G      2.398      1.271     0.8364        230        320: 100%|██████████| 250/250 [00:56<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:10<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.585      0.393      0.419      0.175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      1.21G      2.412      1.252     0.8359        186        320: 100%|██████████| 250/250 [00:56<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:10<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.609       0.41      0.444      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      1.14G      2.399      1.252     0.8318        190        320: 100%|██████████| 250/250 [00:57<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:09<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.593      0.416      0.438      0.178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      1.18G      2.386      1.221     0.8323        293        320: 100%|██████████| 250/250 [00:56<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:09<00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.597      0.429      0.455      0.199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      1.16G      2.272      1.157     0.8281        144        320: 100%|██████████| 250/250 [00:59<00:00,  4.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.602      0.414      0.447      0.192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      1.21G      2.269      1.189     0.8285        218        320: 100%|██████████| 250/250 [00:58<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.586      0.427      0.452      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      1.16G      2.281        1.2     0.8292        270        320: 100%|██████████| 250/250 [00:58<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.572      0.409      0.434      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      1.15G      2.291      1.196     0.8276        250        320: 100%|██████████| 250/250 [00:57<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:08<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.638      0.444      0.489      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      1.18G      2.275      1.204     0.8261        322        320: 100%|██████████| 250/250 [00:57<00:00,  4.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.584      0.417      0.444       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100      1.19G      2.282       1.18     0.8266        265        320: 100%|██████████| 250/250 [00:58<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.624      0.428      0.467      0.195\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100      1.23G      2.255      1.133     0.8205        234        320: 100%|██████████| 250/250 [00:58<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.664      0.457      0.505      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      1.17G      2.196      1.105     0.8198        249        320: 100%|██████████| 250/250 [00:55<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:10<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.599      0.438      0.469      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      1.18G      2.221       1.12     0.8215        340        320: 100%|██████████| 250/250 [00:55<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:09<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.634       0.44      0.483      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      1.17G      2.235       1.14     0.8202        280        320: 100%|██████████| 250/250 [00:56<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:08<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.614      0.427      0.466      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100       1.2G        2.2      1.124     0.8208        316        320: 100%|██████████| 250/250 [00:56<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.645      0.446      0.499      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      1.18G      2.177      1.108     0.8212        401        320: 100%|██████████| 250/250 [00:57<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.655      0.452      0.502      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      1.11G      2.171      1.094     0.8177        279        320: 100%|██████████| 250/250 [00:58<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.633      0.455       0.49      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100      1.18G      2.168      1.073     0.8182        195        320: 100%|██████████| 250/250 [00:58<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.626      0.447       0.49      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      1.18G      2.156      1.072     0.8161        182        320: 100%|██████████| 250/250 [00:58<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.633      0.464      0.506      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      1.23G      2.152      1.068      0.816        172        320: 100%|██████████| 250/250 [00:59<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172       0.65      0.452      0.502      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      1.15G      2.142      1.072     0.8189        249        320: 100%|██████████| 250/250 [00:57<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:08<00:00,  3.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.633      0.452      0.495      0.214\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 18, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "28 epochs completed in 0.542 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 40.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 40.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.63 🚀 Python-3.11.11 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11m summary (fused): 303 layers, 20,031,574 parameters, 0 gradients, 67.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:12<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        250      13172      0.664      0.457      0.505      0.224\n",
            "                 apple        139       5690      0.701      0.583      0.631      0.269\n",
            "                citrus        111       7482      0.626       0.33       0.38      0.179\n",
            "Speed: 0.2ms preprocess, 6.9ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = r\"/content/model\"\n",
        "os.makedirs(model_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "szKZh5cDCZPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(model_path+\"/trained_yolo_model.pt\")"
      ],
      "metadata": {
        "id": "JApIg81sSATc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}